import os
import sys
import json
from pathlib import Path

# Add backend to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../')))

from app.pipeline.parsing.parser import DocxParser
from app.pipeline.normalization.normalizer import Normalizer
from app.pipeline.structure_detection.detector import StructureDetector
from app.pipeline.classification.classifier import ContentClassifier

def main(input_path):
    print(f"\nüöÄ PHASE 1: FIGURE DETECTION")
    print(f"Target: {input_path}")
    
    if not os.path.exists(input_path):
        print(f"‚ùå ERROR: File not found: {input_path}")
        return
    
    # 1. Pipeline Execution
    parser = DocxParser()
    normalizer = Normalizer()
    detector = StructureDetector()
    classifier = ContentClassifier()
    
    doc = parser.parse(input_path, "test_job")
    doc = normalizer.process(doc)
    doc = detector.process(doc)
    doc = classifier.process(doc)
    
    # 2. Analysis
    figures = doc.figures
    
    # 3. Save Output
    output_dir = Path("manual_tests/outputs")
    output_dir.mkdir(parents=True, exist_ok=True)
    output_file = output_dir / "04_figures.json"
    
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump({
            "summary": {
                "figures_detected": len(figures)
            },
            "figures": [fig.model_dump() for fig in figures]
        }, f, indent=2)
    
    print(f"\n--- Analysis Summary ---")
    print(f"Figures Detected: {len(figures)}")
    print(f"------------------------")
    print(f"\n‚úÖ SUCCESS: Result saved to {output_file}")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python run_figure_detection.py <docx_path>")
        sys.exit(1)
    main(sys.argv[1])
